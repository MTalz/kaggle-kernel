{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":487,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load into Pandas dataframe\ntitanic_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n#pd.set_option('display.max_rows',None)\n\n# Load test data\ntitanic_test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntitanic_data.head()","execution_count":488,"outputs":[{"output_type":"execute_result","execution_count":488,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make copy\ntitanic_train = titanic_data\ntitanic_test = titanic_test_data\n\n# Drop PassengerId since non-predictive\ntitanic_train = titanic_train.drop(['PassengerId'],axis=1)\ntitanic_test = titanic_test.drop(['PassengerId'],axis=1)\n\n# Extract Cabin information\ntitanic_train['CabinLetter'] = titanic_train['Cabin'].str.extract(pat='([A-G])')\ntitanic_train = titanic_train.drop(['Cabin'],axis=1)\n\ntitanic_test['CabinLetter'] = titanic_test['Cabin'].str.extract(pat='([A-G])')\ntitanic_test = titanic_test.drop(['Cabin'],axis=1)\n\ntitanic_train['CabinLetter'] = titanic_train['CabinLetter'].fillna('Unknown')\ntitanic_test['CabinLetter'] = titanic_test['CabinLetter'].fillna('Unknown')\n\n# Combine Siblings and Parents\ntitanic_train['Family_num'] = titanic_train['SibSp'] + titanic_train['Parch']\ntitanic_test['Family_num'] = titanic_test['SibSp'] + titanic_test['Parch']\ntitanic_train = titanic_train.drop(['SibSp','Parch'],axis=1)\ntitanic_test = titanic_test.drop(['SibSp','Parch'],axis=1)\n\n# Fare per person\ntitanic_train['Fpp'] = titanic_train['Fare']/(titanic_train['Family_num']+1)\ntitanic_train = titanic_train.drop(['Fare'],axis=1)\ntitanic_test['Fpp'] = titanic_test['Fare']/(titanic_test['Family_num']+1)\ntitanic_test = titanic_test.drop(['Fare'],axis=1)\n\n# Extract ticket numbers\ntitanic_train['Ticket_num'] = titanic_train['Ticket'].str.extract(pat='(\\d{2,}$)')\ntitanic_test['Ticket_num'] = titanic_test['Ticket'].str.extract(pat='(\\d{2,}$)')","execution_count":489,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract prefactor\ntitanic_train['Ticket'] = titanic_train['Ticket'].str.replace('LINE','LINE ')\ndf2_train = titanic_train['Ticket'].str.extract(pat='(^.+\\s)')\n\ntitanic_test['Ticket'] = titanic_test['Ticket'].str.replace('LINE','LINE ')\ndf2_test = titanic_test['Ticket'].str.extract(pat='(^.+\\s)')\n\n# Cleaning training set\ndf2_train = df2_train[0].str.replace('[^\\w\\s]','')\ndf2_train = df2_train.str.replace(' ','')\ndf2_train = df2_train.str.replace('SCParis','SCPARIS')\ndf2_train = df2_train.str.replace('STONO2','SOTONO2')\n\ndf2_test = df2_test[0].str.replace('[^\\w\\s]','')\ndf2_test = df2_test.str.replace(' ','')\ndf2_test = df2_test.str.replace('SCParis','SCPARIS')\ndf2_test = df2_test.str.replace('STONO2','SOTONO2')\ndf2_test = df2_test.str.replace('STONOQ','SOTONOQ')\n\n# Compare ticket pre in test and train set\ndf2_train = pd.get_dummies(df2_train)\ndf2_test = pd.get_dummies(df2_test)\n\ndf2_test[df2_train.columns.difference(df2_test.columns)] = 0\ndf2_train[df2_test.columns.difference(df2_train.columns)] = 0\n\ndf2_train.sum(axis = 0, skipna = True).sort_values()","execution_count":490,"outputs":[{"output_type":"execute_result","execution_count":490,"data":{"text/plain":"SCA3          0\nAQ4           0\nAQ3           0\nA2            0\nLP            0\nSP            1\nSOP           1\nSCOW          1\nSCA4          1\nSC            1\nSCAHBasle     1\nAS            1\nFa            1\nFC            1\nCASOTON       1\nPPP           2\nSCAH          2\nSWPP          2\nPP            3\nWEP           3\nSOPP          3\nLINE          4\nFCC           5\nC             5\nSOC           6\nA4            7\nWC           10\nSCPARIS      11\nSOTONOQ      15\nSOTONO2      20\nA5           21\nCA           41\nPC           60\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep largest\nkeep_pre = ['A5','CA','PC','SCPARIS','SOTONO2','SOTONOQ','WC']\ndf2_train = df2_train[keep_pre]\ndf2_test = df2_test[keep_pre]\n\n# Add to dataframes??????????????????\ntitanic_train = pd.concat([titanic_train, df2_train], axis=1)\ntitanic_test = pd.concat([titanic_test, df2_test], axis=1)\n\n# Drop Ticket feature\ntitanic_train = titanic_train.drop(['Ticket'],axis=1)\ntitanic_test = titanic_test.drop(['Ticket'],axis=1)\n\n########################### Drop some info?\ntitanic_train = titanic_train.drop(['CabinLetter'],axis=1)\ntitanic_test = titanic_test.drop(['CabinLetter'],axis=1)","execution_count":491,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract titles from names\ntitle = '(Mr\\.)|(Mrs\\.)|(Miss\\.)|(Master\\.)'#'|(Dr\\.)|(Mlle\\.)|(Don\\.)|(Lady.)|(Sir\\.)|(Col\\.)|(Rev\\.)|(Capt\\.)|(Countess\\.)'\ndf_train = titanic_train['Name'].str.extract(pat=title)\ndf_test = titanic_test['Name'].str.extract(pat=title)\ndf_train = df_train[df_train.columns[0:]].apply(\n    lambda x: ','.join(x.dropna().astype(str)),\n    axis=1\n)\ndf_test = df_test[df_test.columns[0:]].apply(\n    lambda x: ','.join(x.dropna().astype(str)),\n    axis=1\n)\ndf_train = df_train.replace(r'^\\s*$', np.nan, regex=True)\ndf_test = df_test.replace(r'^\\s*$', np.nan, regex=True)\ndf_train = df_train.fillna('Unknown')\ndf_test = df_test.fillna('Unknown')\n\ndf_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)\n\ndf_test[df_train.columns.difference(df_test.columns)] = 0\ndf_train[df_test.columns.difference(df_train.columns)] = 0\n\n# Drop Name feature\ntitanic_train = titanic_train.drop(['Name'],axis=1)\ntitanic_test = titanic_test.drop(['Name'],axis=1)\n\n# Add to dataframe\ntitanic_train = pd.concat([titanic_train, df_train], axis=1)\ntitanic_test = pd.concat([titanic_test, df_test], axis=1)\n\ndf_train.sum(axis = 0, skipna = True)\ndf_test.sum(axis = 0, skipna = True) ","execution_count":492,"outputs":[{"output_type":"execute_result","execution_count":492,"data":{"text/plain":"Master.     21\nMiss.       78\nMr.        240\nMrs.        72\nUnknown      7\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert rest of categorical variables to numeric\ntitanic_train = pd.get_dummies(titanic_train, columns=['Sex','Embarked'])\ntitanic_test = pd.get_dummies(titanic_test, columns=['Sex','Embarked'])\n\ntitanic_train","execution_count":493,"outputs":[{"output_type":"execute_result","execution_count":493,"data":{"text/plain":"     Survived  Pclass   Age  Family_num       Fpp Ticket_num  A5  CA  PC  \\\n0           0       3  22.0           1   3.62500      21171   1   0   0   \n1           1       1  38.0           1  35.64165      17599   0   0   1   \n2           1       3  26.0           0   7.92500    3101282   0   0   0   \n3           1       1  35.0           1  26.55000     113803   0   0   0   \n4           0       3  35.0           0   8.05000     373450   0   0   0   \n..        ...     ...   ...         ...       ...        ...  ..  ..  ..   \n886         0       2  27.0           0  13.00000     211536   0   0   0   \n887         1       1  19.0           0  30.00000     112053   0   0   0   \n888         0       3   NaN           3   5.86250       6607   0   0   0   \n889         1       1  26.0           0  30.00000     111369   0   0   0   \n890         0       3  32.0           0   7.75000     370376   0   0   0   \n\n     SCPARIS  ...  Master.  Miss.  Mr.  Mrs.  Unknown  Sex_female  Sex_male  \\\n0          0  ...        0      0    1     0        0           0         1   \n1          0  ...        0      0    0     1        0           1         0   \n2          0  ...        0      1    0     0        0           1         0   \n3          0  ...        0      0    0     1        0           1         0   \n4          0  ...        0      0    1     0        0           0         1   \n..       ...  ...      ...    ...  ...   ...      ...         ...       ...   \n886        0  ...        0      0    0     0        1           0         1   \n887        0  ...        0      1    0     0        0           1         0   \n888        0  ...        0      1    0     0        0           1         0   \n889        0  ...        0      0    1     0        0           0         1   \n890        0  ...        0      0    1     0        0           0         1   \n\n     Embarked_C  Embarked_Q  Embarked_S  \n0             0           0           1  \n1             1           0           0  \n2             0           0           1  \n3             0           0           1  \n4             0           0           1  \n..          ...         ...         ...  \n886           0           0           1  \n887           0           0           1  \n888           0           0           1  \n889           1           0           0  \n890           0           1           0  \n\n[891 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>Family_num</th>\n      <th>Fpp</th>\n      <th>Ticket_num</th>\n      <th>A5</th>\n      <th>CA</th>\n      <th>PC</th>\n      <th>SCPARIS</th>\n      <th>...</th>\n      <th>Master.</th>\n      <th>Miss.</th>\n      <th>Mr.</th>\n      <th>Mrs.</th>\n      <th>Unknown</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>3.62500</td>\n      <td>21171</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>35.64165</td>\n      <td>17599</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>7.92500</td>\n      <td>3101282</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>26.55000</td>\n      <td>113803</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>8.05000</td>\n      <td>373450</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>13.00000</td>\n      <td>211536</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>30.00000</td>\n      <td>112053</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>5.86250</td>\n      <td>6607</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>30.00000</td>\n      <td>111369</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>7.75000</td>\n      <td>370376</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 23 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set target variable and drop from dataframe\ntitanic_target = titanic_train['Survived'].to_numpy()\ntitanic_train = titanic_train.drop(['Survived'],axis=1)\n\ntitanic_test.shape","execution_count":494,"outputs":[{"output_type":"execute_result","execution_count":494,"data":{"text/plain":"(418, 22)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ntitanic_std = scaler.fit_transform(titanic_train)\ntitanic_test = scaler.fit_transform(titanic_test)\n\n# Deal with NaN values\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp.fit(titanic_std)\ntitanic_std = imp.transform(titanic_std)\nimp.fit(titanic_test)\ntitanic_test = imp.transform(titanic_test)","execution_count":495,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nfrom keras.optimizers import SGD, Adam\n\nmodel = Sequential()\n\nmodel.add(Dense(100, activation='relu', input_shape=(22,)))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nopt = Adam(learning_rate=5e-3)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\nmodel.fit(titanic_std, titanic_target,epochs=150, batch_size=10, verbose=0)\nscore = model.evaluate(titanic_std, titanic_target,verbose=1)","execution_count":496,"outputs":[{"output_type":"stream","text":"28/28 [==============================] - 0s 918us/step - loss: 0.2655 - accuracy: 0.8855\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy scores and metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\nconfusion_matrix(titanic_target,model.predict_classes(titanic_std))","execution_count":497,"outputs":[{"output_type":"execute_result","execution_count":497,"data":{"text/plain":"array([[517,  32],\n       [ 70, 272]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe with predictions\ntitanic_test_data['Survived'] = model.predict_classes(titanic_test)\ntitanic_test_data[['PassengerId','Survived']]\ntitanic_test_data[['PassengerId','Survived']].to_csv(r'\\kaggle\\working\\submission.csv', index = False)","execution_count":498,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}