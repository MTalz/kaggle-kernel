{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":67,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load into Pandas dataframe\ntrain = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\npd.set_option('max_colwidth', 400)\ntest[['id','text']].head()","execution_count":68,"outputs":[{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"   id  \\\n0   0   \n1   2   \n2   3   \n3   9   \n4  11   \n\n                                                                                               text  \n0                                                                Just happened a terrible car crash  \n1                                  Heard about #earthquake is different cities, stay safe everyone.  \n2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n3                                                          Apocalypse lighting. #Spokane #wildfires  \n4                                                     Typhoon Soudelor kills 28 in China and Taiwan  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make copies, drop id column\nX_train = train.drop(['id','target'],axis=1)\ny_train = train.target\nX_test = test.drop(['id'],axis=1)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n# Check if hyperlinks exist\n\nX_train['hyperlink'] = X_train['text'].str.contains('http')\nX_test['hyperlink'] = X_test['text'].str.contains('http')\n\n# Extract number of hashtags and mentions\n\ndef hash_num(text):\n    text = len(re.findall(r\"#(\\w+)\",text))\n    return text\n\ndef ment_num(text):\n    text = len(re.findall(r\"@(\\w+)\",text))\n    return text\n\nX_train['num_hash'] = X_train['text'].apply(hash_num)\nX_train['num_ment'] = X_train['text'].apply(ment_num)\n\nX_test['num_hash'] = X_test['text'].apply(hash_num)\nX_test['num_ment'] = X_test['text'].apply(ment_num)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean up\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\n\n# Remove stopwords\n\nstop_words = stopwords.words('english')\ndef remove_stopwords(text):\n    text = ' '.join([i for i in text.split(' ') if i not in stop_words ])\n    return text\n\n# Stemming\n\nstemmer = SnowballStemmer(\"english\")\ndef stemming(text):\n    text = ' '.join([stemmer.stem(word) for word in text.split()])\n    return text\n\ndef clean_tweet(text):\n    text = re.sub('http\\S+','', text) # remove hyperlinks\n    text = re.sub('@[A-Za-z0-9_]+', '', text) # remove mentions\n    text = re.sub('[?|!|\\'|\"|#]','',text) # remove punctuation\n    text = re.sub('[.|,|)|(|)|\\|/]',' ',text) # remove punctuation\n    text = re.sub('&amp; ','',text)\n    text = re.sub('[0-9]*','', text) # remove numbers\n    text = text.strip().lower()\n    text = remove_stopwords(text)\n    text = stemming(text)\n    return text\n\nX_train['text'] = X_train['text'].apply(clean_tweet)\nX_test['text'] = X_test['text'].apply(clean_tweet)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['keyword','location'],axis=1)\nX_test = X_test.drop(['keyword','location'],axis=1)\nX_train","execution_count":72,"outputs":[{"output_type":"execute_result","execution_count":72,"data":{"text/plain":"                                                                                                 text  \\\n0                                                           deed reason earthquak may allah forgiv us   \n1                                                                forest fire near la rong sask canada   \n2                               resid ask shelter place notifi offic evacu shelter place order expect   \n3                                                         peopl receiv wildfir evacu order california   \n4                                                got sent photo rubi alaska smoke wildfir pour school   \n...                                                                                               ...   \n7608                                                   two giant crane hold bridg collaps nearbi home   \n7609                                     control wild fire california even northern part state troubl   \n7610                                                                         [: utc]km volcano hawaii   \n7611  polic investig e-bik collid car littl portug e-bik rider suffer serious non-lif threaten injuri   \n7612                                         latest: home raze northern california wildfir - abc news   \n\n      hyperlink  num_hash  num_ment  \n0         False         1         0  \n1         False         0         0  \n2         False         0         0  \n3         False         1         0  \n4         False         2         0  \n...         ...       ...       ...  \n7608       True         0         0  \n7609      False         0         2  \n7610       True         0         0  \n7611      False         0         0  \n7612       True         0         0  \n\n[7613 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>hyperlink</th>\n      <th>num_hash</th>\n      <th>num_ment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deed reason earthquak may allah forgiv us</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>forest fire near la rong sask canada</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>resid ask shelter place notifi offic evacu shelter place order expect</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>peopl receiv wildfir evacu order california</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>got sent photo rubi alaska smoke wildfir pour school</td>\n      <td>False</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>two giant crane hold bridg collaps nearbi home</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>control wild fire california even northern part state troubl</td>\n      <td>False</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>[: utc]km volcano hawaii</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>polic investig e-bik collid car littl portug e-bik rider suffer serious non-lif threaten injuri</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>latest: home raze northern california wildfir - abc news</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount = CountVectorizer()\n\nbow_train = count.fit_transform(X_train.text)\nfeature_train = count.get_feature_names()\n\nbow_test = count.fit_transform(X_test.text)\nfeature_test = count.get_feature_names()","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([pd.DataFrame(bow_train.toarray(), columns=feature_train),\n                     pd.get_dummies(X_train.hyperlink,prefix='hyper'),\n                    X_train.num_hash,\n                    X_train.num_ment], axis=1)\nX_test = pd.concat([pd.DataFrame(bow_test.toarray(), columns=feature_test),\n                     pd.get_dummies(X_test.hyperlink,prefix='hyper'),\n                    X_test.num_hash,\n                    X_test.num_ment], axis=1)","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[X_train.shape,X_test.shape]","execution_count":75,"outputs":[{"output_type":"execute_result","execution_count":75,"data":{"text/plain":"[(7613, 11606), (3263, 7296)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X_train.columns.difference(X_test.columns):\n    X_test[col]=0\nfor col in X_test.columns.difference(X_train.columns):\n    X_train[col]=0","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB(alpha=1)\nnb.fit(X_train, y_train)\ny_pred = pd.DataFrame(nb.predict(X_test),columns=['target'])","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Export predictions to csv\nres = pd.concat([test.id,y_pred.target],axis=1)\nres.to_csv(r'\\kaggle\\working\\submission.csv', index = False)\nres","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"         id  target\n0         0       1\n1         2       0\n2         3       0\n3         9       0\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       0\n3261  10874       0\n3262  10875       0\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}